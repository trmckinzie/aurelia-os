---
created: 2025-12-31
tags:
  - type/concept
  - topic/systems
  - topic/adaptation
  - topic/cognitive-science
  - topic/computation
  - topic/learning
  - topic/phil-mind
publish: true
---
# ‚öõÔ∏è Valence

**üîó Related:** [[Reinforcement Learning]], [[Reward Prediction Error]], [[Homeostasis]], [[Dopamine]], [[Value Function]], [[Qualia]]

---

### üí° Definition
> The intrinsic "sign" or directional value assigned to a sensory state, categorizing it as attractive (positive) or aversive (negative). In **Machine Learning**, specifically Reinforcement Learning, valence is encoded as the scalar reward signal $R_t$ or the estimated Value Function $V(s)$ that the agent maximizes. In **Biological Systems**, valence is the subjective experience of pleasure or pain‚Äîthe evolutionary shorthand that labels inputs as "fitness-enhancing" or "fitness-reducing" without requiring the organism to understand the underlying causality.

### üìù Key Insight
* **The Compass of Action:** [[Intelligence]] is distinct from mere [[Computation]] because of valence. A computer can process data about a fire (temperature, brightness) indefinitely without acting. An intelligent agent (biological or artificial) only acts when that data is assigned a **negative valence** (pain/cost). Therefore, valence is the [[mechanism]] that transforms "Is" (objective reality) into "Ought" (behavioral imperative). In the brain, **[[Dopamine]]** does not signal the valence itself (pleasure), but the _error_ in predicting it (Reward Prediction Error), driving the learning process.

---

